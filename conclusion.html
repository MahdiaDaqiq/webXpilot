<html>
<head>
  <meta charset="UTF-8">
  <link href="web.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="main_style.css">
  <link rel="stylesheet" type="text/css" href="Conclusion.css">

</head>
<body>  
   <header>
    <nav>
      <figure>
        <a href="index.html">
          <img src="https://i0.wp.com/www.photoshopsupply.com/wp-content/uploads/2019/05/triangle-shape-1.jpg?w=1140&ssl=1">
        </a>
      </figure>

      <h1><p>AN EVOLVING XPILOT FUZZY AGENT</p></h1>

      <div class="DropDown-Menu">
        <ul>
          <li>Project <i class="fa fa-caret-down"></i>
            <ul> 
              <a href="descrption.html">Description</a>
              <a href="reference.html">Reference</a>
              <a href="aboutUs.html">About Us</a>
            </ul>
          </li>
          <li>Methods<i class="fa fa-caret-down"></i>
            <ul>
              <a href="step-By-Step.html">Step-By-Step</a>
            </ul>
          </li>
          <li>Results <i class="fa fa-caret-down"></i>
            <ul>
              <a href="data.html">Data/Results</a>
              <a href="conclusion.html">Conclusion</a>
            </ul>
          </li>
        </ul>
      </div>
    </nav>
  </header>
  <div class="Conclusion">
    <h1>Conclusion</h1>
    <h2>Discussion of Results</h2>
    <p> After doing some short training on Dumpster, the fuzzy xpilot agent, it is clear that it is possible to train the agent to learn the best fuzzy to beat its opponent. If given enough time to run around, the fuzzy agent will learn how to adjustt its fuzzy logic so that it doesn't run into walls. The same thing applies for bullet avoidance and killing. The hardest part of the project was definetly to make the training environment and the fitness function as good as possible for the robot to learn the desired behavior. Our training environment didn't switch the position of the agent, and when we tried to move the agent to different positions the fitness function became extremely difficult to implement and to calculate a fair fitness between the starting points. The other major difficulty was too find an aggressive agent that is not overly aggressive so that some learnin can take place. Possible solutions might have been to use a much bigger map or farther sponing spots. It was also difficult to find a perfect fitness function to make the agent prioritize killing but also survival. Finding a balance of point distribution between survival time and killing time was relatively laborious. At least, the training has shown some improvement for both Rabbit and Dumpster, which was somewhat great even though it was not as great as expected. Some more training with different fitness functions and maybe some more rules to the agents would have been great, but due to time issues it was not possible.    
    </p>
    <h2>Future Work</h2> 
    <p>Rabbit was estblish to be the more defensive type agent that our fuzzy agent would play against. To make it relatively defensive, we developed a genetic algorithm that has a fitness score based on survival. Basically, Rabbit would get points for the longer it stays alive and some minor penalties if it gets killed by the other agent or if it crashes into a wall. It was crucial to make Rabbit learn before it faced Dumpster as the goal was to have Dumpster play a smartt defensive agent. The training of Rabbit was done against one of the robots that the xpilot game push into the game when allowed. These robots are extremely aggressive as they tend to follow and attack the opposing robot right away and it does not give up until it either dies or make the kill. The results of the training were relatively good. Rabbit learned how to stay alive longer over time until it hit a certain point in its learning.The following variables were coontrolled inside the production system by the genetic algorithm: frontwall_Alert, backwall_Alert, slowtrackwall_Alert, fasttrackwall_Alert, Enemy_Alert and finally Bullet_alert. All of these variables were necessary for the wall avoidance rules, the bullet avoidance rules, the shooting rules and the turning rules. The genetic algorithm as composed of 32 chromosmes total with a population totalling 64 individuals for each generation. A crossover rate of 70% and a mutation rate of 1% were used during training. The selection process was done by choosing the individuals with a better fitness. In other words, the more fitted an individual was the more chance the individual would have to reproduce and even survive. 
    </p> 
  </div>


  </body>


